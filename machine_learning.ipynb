{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 계산 함수 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index = ['l_fg','l_fist','l_tb','r_fg','r_fist','r_tb'], \n",
    "                         columns = ['l_fg','l_fist','l_tb','r_fg','r_fist','r_tb'])\n",
    "    #Plotting the confusion matrix\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('RandomForest')\n",
    "    plt.ylabel('Actal Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "def print_auc_roc(model, x_test):\n",
    "    global y_test\n",
    "    #Calculate the y_score\n",
    "    y_score = model.predict_proba(x_test)\n",
    "    #Binarize the output\n",
    "    y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "    n_classes = y_test_bin.shape[1]\n",
    "\n",
    "    sum=0\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    fpr_sum=[]\n",
    "    tpr_sum=[]\n",
    "\n",
    "\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        fpr_sum.append(fpr[i])\n",
    "        tpr_sum.append(tpr[i])\n",
    "        #plt.plot(fpr[i], tpr[i], color=colors[i], lw=2)\n",
    "        print('AUC for Class {}: {}'.format(i, auc(fpr[i], tpr[i])))\n",
    "        sum+=auc(fpr[i], tpr[i])\n",
    "        \n",
    "    print(\"average sum:\", sum/3)\n",
    "    fpr_avg=[]\n",
    "    tpr_avg=[]\n",
    "    for i in range(max(fpr_sum[0].shape[0],fpr_sum[1].shape[0],fpr_sum[2].shape[0])):\n",
    "        num=0\n",
    "        sum2=0\n",
    "        if i< fpr_sum[0].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=fpr_sum[0][i]\n",
    "        if i< fpr_sum[1].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=fpr_sum[1][i]\n",
    "        if i< fpr_sum[2].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=fpr_sum[2][i]\n",
    "\n",
    "        fpr_avg.append(sum2/num)\n",
    "\n",
    "    for i in range(max(tpr_sum[0].shape[0],tpr_sum[1].shape[0],tpr_sum[2].shape[0])):\n",
    "        num=0\n",
    "        sum2=0\n",
    "        if i< tpr_sum[0].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=tpr_sum[0][i]\n",
    "        if i< tpr_sum[1].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=tpr_sum[1][i]\n",
    "        if i< tpr_sum[2].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=tpr_sum[2][i]\n",
    "\n",
    "        tpr_avg.append(sum2/num)\n",
    "        \n",
    "    return fpr_avg, tpr_avg\n",
    "    #plt.plot(fpr_avg, tpr_avg, color='blue', lw=2)\n",
    "\n",
    "    #plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('Receiver Operating Characteristic Curves')\n",
    "    #plt.show()\n",
    "\n",
    "def print_pr_curve(model, x_test):\n",
    "    #Calculate the y_score\n",
    "    y_score = model.predict_proba(x_test)\n",
    "    #Binarize the output\n",
    "    y_test_bin = label_binarize(y_test, classes=[0,1,2])\n",
    "    n_classes = y_test_bin.shape[1]\n",
    "\n",
    "    sum=0\n",
    "    pr = dict()\n",
    "    rc = dict()\n",
    "    #roc_auc = dict()\n",
    "    pr_sum=[]\n",
    "    rc_sum=[]\n",
    "\n",
    "    pr_avg=[]\n",
    "    rc_avg=[]\n",
    "\n",
    "\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    for i in range(n_classes):\n",
    "        pr[i], rc[i], _ = precision_recall_curve(y_test_bin[:, i], y_score[:, i])\n",
    "        base_rate=y_score[:, i].mean()\n",
    "        pr_sum.append(pr[i])\n",
    "        rc_sum.append(rc[i])\n",
    "        #plt.plot(rc[i], pr[i], color=colors[i], lw=2)\n",
    "\n",
    "    for i in range(max(pr_sum[0].shape[0],pr_sum[1].shape[0],pr_sum[2].shape[0])):\n",
    "        num=0\n",
    "        sum2=0\n",
    "        if i< pr_sum[0].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=pr_sum[0][i]\n",
    "        if i< pr_sum[1].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=pr_sum[1][i]\n",
    "        if i< pr_sum[2].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=pr_sum[2][i]\n",
    "\n",
    "        pr_avg.append(sum2/num)\n",
    "\n",
    "    for i in range(max(rc_sum[0].shape[0],rc_sum[1].shape[0],rc_sum[2].shape[0])):\n",
    "        num=0\n",
    "        sum2=0\n",
    "        if i< rc_sum[0].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=rc_sum[0][i]\n",
    "        if i< rc_sum[1].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=rc_sum[1][i]\n",
    "        if i< rc_sum[2].shape[0]:\n",
    "            num+=1\n",
    "            sum2+=rc_sum[2][i]\n",
    "\n",
    "        rc_avg.append(sum2/num)\n",
    "        \n",
    "    return pr_avg, rc_avg\n",
    "\n",
    "\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('Recall')\n",
    "    #plt.ylabel('Precision')\n",
    "    #plt.title('Precision-Recall Curve')\n",
    "    #plt.show()\n",
    "\n",
    "def print_feature_importances(model, train_data):\n",
    "    importances=model.feature_importances_\n",
    "    indices=np.argsort(importances)[::-1]\n",
    "\n",
    "    print('Feature ranking:')\n",
    "\n",
    "    for f in range(train_data.shape[1]):\n",
    "        print('{}. feature {} ({:.3f})'.format(f+1, train_data.columns[indices][f], importances[indices[f]]))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title('feature importances')\n",
    "    plt.bar(range(train_data.shape[1]), importances[indices],\n",
    "            color='r', align='center')\n",
    "    for i,v in enumerate(range(train_data.shape[1])):\n",
    "        plt.text(v, importances[indices][i],round(importances[indices][i],2), fontsize=9, color='black', horizontalalignment='center', verticalalignment='bottom')\n",
    "    plt.xticks(range(train_data.shape[1]), train_data.columns[indices], rotation=45)\n",
    "    plt.xlim([-1,train_data.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pp=pd.read_csv('./data/total_pp-1_aug_keypoint.csv')\n",
    "cnv=pd.read_csv('./data/cnv_total-2_aug_keypoint.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keypoint data와 label data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_X,pp_Y=pp.iloc[:,1:],pp.iloc[:,:1]\n",
    "cnv_X,cnv_Y=cnv.iloc[:,1:],cnv.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data, train data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#train data와 test data로 나눔,비율은 80 20으로\n",
    "pp_X_train, pp_X_test, pp_y_train, pp_y_test = train_test_split(pp_X,pp_Y, test_size=0.2, stratify=pp_Y)\n",
    "cnv_X_train, cnv_X_test, cnv_y_train, cnv_y_test = train_test_split(cnv_X,cnv_Y, test_size=0.2, stratify=cnv_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기- xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pp========\n",
      "precision: 0.3976948101948101\n",
      "recall: 0.37409145303882146\n",
      "f1: 0.38004726777000597\n",
      "========cnv========\n",
      "precision: 0.5962167096324597\n",
      "recall: 0.5948282722179781\n",
      "f1: 0.5948569607018018\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model=XGBClassifier()\n",
    "model.fit(pp_X_train, pp_y_train)\n",
    "pp_y_pred=model.predict(pp_X_test)\n",
    "print('========pp========')\n",
    "print('precision:', precision_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('recall:', recall_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('f1:', f1_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "model.save_model('./model/xgboost_total_pp-1.model')\n",
    "\n",
    "model=XGBClassifier()\n",
    "model.fit(cnv_X_train, cnv_y_train)\n",
    "cnv_y_pred=model.predict(cnv_X_test)\n",
    "print('========cnv========')\n",
    "print('precision:', precision_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('recall:', recall_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('f1:', f1_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "model.save_model('./model/xgboost_total_cnv-2.model')\n",
    "\n",
    "# print_confusion_matrix(pp_y_test,pp_y_pred)\n",
    "# a2,b2=print_auc_roc(model, pp_X_test)\n",
    "# c2,d2=print_pr_curve(model, pp_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기 - RandomForestCalssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\AppData\\Local\\Temp\\ipykernel_10352\\3327399677.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(pp_X_train, pp_y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pp========\n",
      "precision: 0.4016958501804269\n",
      "recall: 0.37583995478732324\n",
      "f1: 0.38324641932236864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\AppData\\Local\\Temp\\ipykernel_10352\\3327399677.py:15: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(cnv_X_train, cnv_y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========cnv========\n",
      "precision: 0.6051375332732557\n",
      "recall: 0.5896318754774637\n",
      "f1: 0.5937299259940118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/randomforest_total_cnv-2.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "model.fit(pp_X_train, pp_y_train)\n",
    "pp_y_pred=model.predict(pp_X_test)\n",
    "print('========pp========')\n",
    "print('precision:', precision_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('recall:', recall_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('f1:', f1_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/randomforest_total_pp-1.pkl')\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "model.fit(cnv_X_train, cnv_y_train)\n",
    "cnv_y_pred=model.predict(cnv_X_test)\n",
    "print('========cnv========')\n",
    "print('precision:', precision_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('recall:', recall_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('f1:', f1_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/randomforest_total_cnv-2.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기- GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pp========\n",
      "precision: 0.3290843926547092\n",
      "recall: 0.28999744789218473\n",
      "f1: 0.299386988954406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========cnv========\n",
      "precision: 0.5564010938935522\n",
      "recall: 0.5454524233935999\n",
      "f1: 0.5482909855002878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/GradientBoosting_total_cnv-2.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model=GradientBoostingClassifier()\n",
    "model.fit(pp_X_train, pp_y_train)\n",
    "pp_y_pred=model.predict(pp_X_test)\n",
    "print('========pp========')\n",
    "print('precision:', precision_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('recall:', recall_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('f1:', f1_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/GradientBoosting_total_pp-1.pkl')\n",
    "\n",
    "model=GradientBoostingClassifier()\n",
    "model.fit(cnv_X_train, cnv_y_train)\n",
    "cnv_y_pred=model.predict(cnv_X_test)\n",
    "print('========cnv========')\n",
    "print('precision:', precision_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('recall:', recall_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('f1:', f1_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/GradientBoosting_total_cnv-2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기-AdaGradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pp========\n",
      "precision: 0.25671887427017764\n",
      "recall: 0.24307723649828913\n",
      "f1: 0.2373401307280368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========cnv========\n",
      "precision: 0.4254628390477448\n",
      "recall: 0.42478288663950425\n",
      "f1: 0.4239712438921137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/GAdaGradientBoosting_total_cnv-2.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model=AdaBoostClassifier()\n",
    "model.fit(pp_X_train, pp_y_train)\n",
    "pp_y_pred=model.predict(pp_X_test)\n",
    "print('========pp========')\n",
    "print('precision:', precision_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('recall:', recall_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('f1:', f1_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/AdaGradientBoosting_total_pp-1.pkl')\n",
    "\n",
    "model=AdaBoostClassifier()\n",
    "model.fit(cnv_X_train, cnv_y_train)\n",
    "cnv_y_pred=model.predict(cnv_X_test)\n",
    "print('========cnv========')\n",
    "print('precision:', precision_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('recall:', recall_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('f1:', f1_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/GAdaGradientBoosting_total_cnv-2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기 - Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pp========\n",
      "precision: 0.35741166797938345\n",
      "recall: 0.3367876591560803\n",
      "f1: 0.33758340545212756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========cnv========\n",
      "precision: 0.5441163903134378\n",
      "recall: 0.5386383530685002\n",
      "f1: 0.5380236694138378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/Bagging_total_cnv-2.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model=BaggingClassifier()\n",
    "model.fit(pp_X_train, pp_y_train)\n",
    "pp_y_pred=model.predict(pp_X_test)\n",
    "print('========pp========')\n",
    "print('precision:', precision_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('recall:', recall_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('f1:', f1_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/Bagging_total_pp-1.pkl')\n",
    "\n",
    "model=BaggingClassifier()\n",
    "model.fit(cnv_X_train, cnv_y_train)\n",
    "cnv_y_pred=model.predict(cnv_X_test)\n",
    "print('========cnv========')\n",
    "print('precision:', precision_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('recall:', recall_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('f1:', f1_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/Bagging_total_cnv-2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기- ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\AppData\\Local\\Temp\\ipykernel_10352\\1707017880.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(pp_X_train, pp_y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pp========\n",
      "precision: 0.42515128060793694\n",
      "recall: 0.3905769234716603\n",
      "f1: 0.3982953498429165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\limsomi\\AppData\\Local\\Temp\\ipykernel_10352\\1707017880.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(cnv_X_train, cnv_y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========cnv========\n",
      "precision: 0.6065021854152289\n",
      "recall: 0.597504721585604\n",
      "f1: 0.5996298486272096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/ExtraTrees_total_cnv-2.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(pp_X_train, pp_y_train)\n",
    "pp_y_pred=model.predict(pp_X_test)\n",
    "print('========pp========')\n",
    "print('precision:', precision_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('recall:', recall_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "print('f1:', f1_score(pp_y_test, pp_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/ExtraTrees_total_pp-1.pkl')\n",
    "\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(cnv_X_train, cnv_y_train)\n",
    "cnv_y_pred=model.predict(cnv_X_test)\n",
    "print('========cnv========')\n",
    "print('precision:', precision_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('recall:', recall_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "print('f1:', f1_score(cnv_y_test, cnv_y_pred, average='macro'))\n",
    "joblib.dump(model, './model/ExtraTrees_total_cnv-2.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "46252a685a9fce4287c91046ac5d8980da87f1089e0b46453300626a4efb4f53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
